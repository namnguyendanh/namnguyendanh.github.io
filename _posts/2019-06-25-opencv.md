---
title:  "OpenCV"
categories: 
    - technology
tags: 
    - computervision
header:
    image: /images/2019-06-25-opencv/opencv.png
---

## What is OpenCV ?

## Some basic Image Manipulations in Python OpenCV
### Resize
### Crop
### Rotate
```python
# grab the dimensions of the image and calculate the center
# of the image
(h, w) = image.shape[:2]
center = (w / 2, h / 2)
 
# rotate the image by 180 degrees
M = cv2.getRotationMatrix2D(center, 180, 1.0)
rotated = cv2.warpAffine(image, M, (w, h))
cv2.imshow("rotated", rotated)
cv2.waitKey(0)

```

**References**: https://www.pyimagesearch.com/2014/01/20/basic-image-manipulations-in-python-and-opencv-resizing-scaling-rotating-and-cropping/

### Threshold

### Find Contours
### Draw Contours

### Bilateral Filter
- Remove noise in the image while still preserving the actual edges.

### Canny Edge Detector

### arcLength
- Tính chu vi của contour

### approxPolyDP

**References**:
- https://docs.opencv.org/3.1.0/dd/d49/tutorial_py_contour_features.html

### Perspective Transform
- Using `getPerspectiveTransform` and `warpPerspective`

**References**:
- https://www.pyimagesearch.com/2014/05/05/building-pokedex-python-opencv-perspective-warping-step-5-6/

### Color Histogram
**Reference**: https://www.pyimagesearch.com/2014/01/22/clever-girl-a-guide-to-utilizing-color-histograms-for-computer-vision-and-image-search-engines/

## Some Image Descriptors

### Color
- Invariant to scale and rotation.

### Texture
- Ex: HoG

### Shape
- Ex: Hu Moments.

## Some Terminologies
- **Image descriptor**: are used to extract features from images. -> *feature vector*
- CBIR: Content Based Image Retrieval systems.
- HoG: Histogram of Oriented Gradients.

## Some Distance Metrics
- Euclidean
- Manhattan
- Chebyshev
- Cosine
- Hamming

To create custom distance metrics -> prove all the properties of distance metrics.














## DEPTH CAMERA 

Depth Camera: Camera RGB với cảm biến chiều sâu giúp có thêm thông tin về không gian 3D bên ngoài, thường ứng dụng trong bài toán Object Detection. Ví dụ: Microsoft Kinect (dùng cho Xbox 360 và Xbox One), Orbbec Astra (dùng trong "Cuộc đua số" của FPT nếu em ko nhầm) Sự xuất hiện của những kênh liên quan đến chiều sâu dẫn đến một số khái niệm: 

**Depth map**: là một ảnh grayscale, giá trị của mỗi pixel phản ánh khoảng cách từ camera đến vật thể. 

**Point cloud map**: là ảnh màu BGR, mỗi màu phản ánh vị trí (B - right, G - up, R - depth) từ góc nhìn của camera. 

**Disparity map**: là ảnh grayscale, mà mỗi giá trị của pixel là "stereo disparity". Giả sử ta có 2 ảnh chụp cùng một cảnh với 2 góc nhìn khác nhau. Với mỗi điểm của vật thể giống nhau dưới 2 góc nhìn ấy, ta tính được khoảng cách (đo bằng pixel) -> Vật ở gần sẽ có "stereo disparity" lớn hơn là vật ở xa. 

**Valid depth mask**: kiểm tra xem thông tin về chiều sâu ở một pixel nào đó là valid hay invalid. Ví dụ, thông tin chiều sâu ở vùng mà bị khuất (tia hồng ngoại không chiếu tới) thì sẽ invalid. 

## DEPTH ESTIMATION WITH A NORMAL CAMERA. 

Có một giải pháp không sử dụng cảm biến hồng ngoại trong việc ước lượng chiều sâu. Đó là Epipolar Geometry - geometry for stereo vision. Cụ thể là thuật toán semiglobal block matching (trong OpenCV là hàm StereoSGBM), thuật toán này dùng để tính toán disparity map. Stereo Vision là một nhánh của Computer Vision, xử lý vấn đề thu nhận thông tin 3D từ 2 bức ảnh khác nhau chụp cùng một vật thể. 

## OBJECT SEGMENTATION WITH GRABCUT ALGORITHMS 

Việc tính toán disparity map (bằng StereoSGBM) có thể giúp nhận diện được tiền cảnh (foreground) trong một bức ảnh. Ngoài ra, còn có thuật toán GrabCut. Các bước của thuật toán Grab Cut: 

Tạo hình chữ nhật bao quanh các vật thể trong bức ảnh 

Vùng nằm ngoài hình chữ nhật sẽ coi là background. 

Dữ liệu từ background ấy sẽ được lấy để phân biệt vùng background còn sót trong hình chữ nhật chứa vật thể. 

Dùng Gaussians Mixture Models để gắn nhãn các undefined pixel xem có thể là foreground hay background. (đoạn này em chưa hiểu lắm) 

Mỗi pixel liên kết với pixel liền kề qua virtual edges, mỗi cái edge đấy sẽ chứa xác suất foreground/backgrounddựa trên sự đồng màu với các pixel xung quanh. 

Mỗi pixel (node) sẽ liên kết với background hoặc foreground node. 

Chia ảnh thành background và foreground. 