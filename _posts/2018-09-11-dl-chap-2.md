---
title:  "Deep Learning Book - Chap 2: Linear Algebra"
categories: 
    - machinelearning
---
# Chapter 2: Linear Algebra
Đại số tuyến tính rất cần thiết trong việc hiểu và làm việc với Machine Learning và đặc biệt là Deep Learning.

Linear Algebra tương đương với học phần Math II của ICT.

Ở bài này, mình chỉ tóm tắt lại hoặc lược qua tiêu đề một số phần do biết trước rồi, hoặc để tự nghiên cứu sau.

Đại số tuyến tính liên quan đến một số đối tượng:
- Scalars
- Vectors
- Matrices
- Tensors

Có một số phép toán trên ma trận quan trọng như: transpose(chuyển vị), nhân ma trận, hay *broadcasting* (trong phạm vị Deep Learning)

System of linear equations (Hệ phương trình): $\mathbf{Ax} = \mathbf{b}$

Ngoài ra còn một số khái niệm quan trọng:
- Identity, Inverse Matrices
- Linear Dependence, Span
- Norms 
- Diagonal matrix
- Symmetric matrix
- Orthogonal matrix

Nhiều đối tượng toán có thể được hiểu tốt hơn bằng cách phân tách nó thành những thành phẩn, rồi tìm ra đặc tính của chúng. 

*Eigendecomposition* là một cách để phân tách ma trận thành tập những eigenvectors và eigenvalues.

*Singular Value Decomposition* phân tách ma trận thành singular vectors và singular values.

Không phải ma trận nào cũng có ma trận nghịch đảo, thế nên ta dùng Moore-Penrose pseudoinverse.

Một số hàm làm việc với ma trận:
- Trace
- Determinant

### Principal Components Analysis (PCA)
PCA là một thuật toán ML đơn giản có thể xây dựng chỉ với những kiến thức cơ bản về Đại số tuyến tính.

Đọc kỹ về PCA tại [đây](https://machinelearningcoban.com/2017/06/15/pca/)



