{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3: Probability and Information Theory\n",
    "Lý thuyết thống kê dùng để biểu diễn những mệnh đề không chắc chắn (uncertain statements)\n",
    "Dùng cho ML là bởi ML luôn phải làm việc với những định lượng không chắc chắn, hay ngẫu nhiên.\n",
    "\n",
    "Lý thuyết thống kê có 2 trường phái:\n",
    "- Frequentist probability\n",
    "- Bayesian probability (dùng degree of belief)\n",
    "\n",
    "## Biến ngẫu nhiên\n",
    "- discrete\n",
    "- continuous\n",
    "\n",
    "## Phân bố xác suất\n",
    "### Probability Mass Functions với biến rời rạc\n",
    "### Probability Density Functions với biến liên tục\n",
    "\n",
    "## Marginal Probability\n",
    "## Conditional Probability\n",
    "## The Chain Rule of Conditional Probabilities\n",
    "## Independence and Conditional Independence\n",
    "\n",
    "## Expectation, Variance and Covariance\n",
    "**Giá trị kỳ vọng** là giá trị trung bình của biến $x$ với $P(X)$\n",
    "-> Giá trị kỳ vọng của hàm số $f(X)$ là giá trị trung bình mà f nhận được từ $x$ với $P(X)$. \n",
    "-> Expectation of discrete/continuous variables.\n",
    "\n",
    "**Variance** tính độ dao động của biến $x$.\n",
    "\n",
    "**Covariance** tính độ liearly related của 2 biến\n",
    "- 2 biến độc lập có zero covariance và ngược lại. (vẫn có trường hợp 2 biến phụ thuộc nhưng zero covariance)\n",
    "\n",
    "**Covariance matrix**\n",
    "\n",
    "## Common Probability Distributions\n",
    "### Bernoulli Distribution\n",
    "### Multinoulli Distribution\n",
    "### Gaussian Distribution\n",
    "### Exponential and Laplace Distributions\n",
    "### The Dirac Distribution and Empirical Distribution\n",
    "### Mixtures of Distributions\n",
    "\n",
    "## Useful Properties of Common Functions\n",
    "Một số hàm cần thiết trong quá trình làm việc với phân bố xác suất, đặc biệt là các phân bố dùng trong DL\n",
    "\n",
    "- Logistic sigmoid.\n",
    "- Softplus\n",
    "\n",
    "## Bayes' Rule\n",
    "## Technical Details of Continuous Variables\n",
    "\n",
    "## Information Theory\n",
    "Self-information\n",
    "\n",
    "**Shannon entropy**: quantify the amount of uncertainty in an entire probability distribution\n",
    "**Kullback-Leibler (KL) divergence**: measure how different these two distributions\n",
    "**Cross-entropy**: similar to KL divergence\n",
    "\n",
    "## Structured Probabilistic Models\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
